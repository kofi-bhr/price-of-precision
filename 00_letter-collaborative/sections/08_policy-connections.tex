\section{Connections to Policy Discussions}

Our theoretical framework connects to several puzzling features of real-world algorithmic bias:

\textbf{Persistence Despite Awareness.} Our model explains why bias might persist even when firms are aware of it and face public pressure to eliminate it. If the bias provides valuable information, eliminating it entirely may be privately costly.

\textbf{Cross-Industry Variation.} Industries with more complex prediction tasks (where the fairness-accuracy trade-off is steeper) should exhibit more bias, consistent with anecdotal evidence from hiring, lending, and criminal justice applications.

\textbf{Policy Resistance.} Simple fairness mandates may be ineffective or counterproductive if they force firms to use inferior information technologies. More sophisticated interventions that address the underlying technology constraints may be necessary.

\textbf{Innovation Incentives.} Our framework suggests that investments in ``fair AI" research should focus not just on eliminating bias, but on developing techniques that achieve fairness without sacrificing accuracy.